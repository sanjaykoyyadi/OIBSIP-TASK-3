# ============================================
# PROJECT: Predicting House Prices with Linear Regression
# AUTHOR: Gaini Saiteja
# DESCRIPTION:
#   Build a predictive model using Linear Regression
#   to estimate house prices based on dataset features.
# ============================================

# -------------------------------
# STEP 1: Import Required Libraries
# -------------------------------
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

# -------------------------------
# STEP 2: Load the Dataset
# -------------------------------
df = pd.read_csv("Housing.csv")   # <- your dataset filename
print("âœ… Dataset Loaded Successfully!\n")

# Display basic info
print("Shape of Data:", df.shape)
print("\nColumn Info:\n", df.dtypes)
print("\nMissing Values:\n", df.isnull().sum())
print("\nFirst 5 Rows:\n", df.head())

# -------------------------------
# STEP 3: Data Exploration
# -------------------------------
print("\nStatistical Summary:\n", df.describe())

# Correlation heatmap for numeric columns only
plt.figure(figsize=(8,6))
numeric_df = df.select_dtypes(include=[np.number])
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap (Numeric Features Only)")
plt.show()


# -------------------------------
# STEP 4: Define Target and Features
# -------------------------------
target = 'price'   # Target variable
X = df.drop(columns=[target])
y = df[target]

# Check categorical columns
categorical_cols = X.select_dtypes(include=['object']).columns
print("\nCategorical Columns:", categorical_cols.tolist())

# One-hot encode categorical variables
X = pd.get_dummies(X, drop_first=True)

# -------------------------------
# STEP 5: Split Data into Train and Test
# -------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
print("\nTraining Samples:", X_train.shape[0])
print("Testing Samples:", X_test.shape[0])

# -------------------------------
# STEP 6: Feature Scaling
# -------------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# -------------------------------
# STEP 7: Train Linear Regression Model
# -------------------------------
model = LinearRegression()
model.fit(X_train_scaled, y_train)

print("\nâœ… Linear Regression Model Trained Successfully!")

# -------------------------------
# STEP 8: Model Evaluation
# -------------------------------
y_pred_train = model.predict(X_train_scaled)
y_pred_test = model.predict(X_test_scaled)

# Calculate evaluation metrics
mse_train = mean_squared_error(y_train, y_pred_train)
mse_test = mean_squared_error(y_test, y_pred_test)
rmse_train = np.sqrt(mse_train)
rmse_test = np.sqrt(mse_test)
mae_test = mean_absolute_error(y_test, y_pred_test)
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)

print("\nðŸ“Š Model Performance Summary:")
print(f"Train RÂ² Score: {r2_train:.4f}")
print(f"Test RÂ² Score:  {r2_test:.4f}")
print(f"Test RMSE:      {rmse_test:.2f}")
print(f"Test MAE:       {mae_test:.2f}")

# -------------------------------
# STEP 9: Visualizations
# -------------------------------

# 1. Predicted vs Actual
plt.figure(figsize=(7,6))
plt.scatter(y_test, y_pred_test, alpha=0.7)
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'r--', lw=2)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Predicted vs Actual House Prices")
plt.show()

# 2. Residuals Plot
residuals = y_test - y_pred_test
plt.figure(figsize=(7,6))
sns.scatterplot(x=y_pred_test, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted Price")
plt.ylabel("Residuals")
plt.title("Residuals vs Predicted Values")
plt.show()

# 3. Residuals Distribution
plt.figure(figsize=(7,5))
sns.histplot(residuals, kde=True, bins=25)
plt.title("Residuals Distribution")
plt.xlabel("Error (Actual - Predicted)")
plt.show()

# -------------------------------
# STEP 10: Feature Importance
# -------------------------------
coefficients = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': model.coef_
}).sort_values(by='Coefficient', ascending=False)

print("\nTop Features Affecting Price:\n", coefficients.head(10))

# -------------------------------
# STEP 11: Sample Predictions
# -------------------------------
pred_df = pd.DataFrame({
    'Actual Price': y_test.values,
    'Predicted Price': y_pred_test,
    'Residual': residuals
})
print("\nSample Predictions:\n", pred_df.head(10))

# -------------------------------
# STEP 12: Save Results
# -------------------------------
coefficients.to_csv("coefficients.csv", index=False)
pred_df.to_csv("sample_predictions.csv", index=False)

print("\nâœ… Results saved as 'coefficients.csv' and 'sample_predictions.csv'")
